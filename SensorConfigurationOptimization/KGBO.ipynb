{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SensorOptimizers.BayesianOptimization as bo\n",
    "import numpy as np\n",
    "import pickle\n",
    "import Config as cf\n",
    "\n",
    "maxSensorNum = int(np.min([(cf.space[2][0] / cf.epsilon) * (cf.space[2][1] / cf.epsilon), cf.LSsensorsNum]))\n",
    "\n",
    "\n",
    "print('----- Running BO with: \\n \\t - epsilon: ', cf.epsilon, \n",
    "      '\\n \\t - testbed: ', cf.testbed,\n",
    "      '\\n \\t - LS sensors #: ', cf.LSsensorsNum, \n",
    "      '\\n \\t - IS sensors #: ', cf.ISsensorsNum, \n",
    "      '\\n \\t - initial state: ', cf.initial_state,\n",
    "      '\\n \\t - gradient analysis: ', cf.gradient_fantacy,\n",
    "      ' \\n \\t - AF: ', cf.acquisition_function)\n",
    "\n",
    "for i in range(0, 1):\n",
    "    BO = bo.BayesianOptimization(testbed = cf.testbed,\n",
    "                                 iteration = cf.bo_iteration, \n",
    "                                 epsilon = cf.epsilon, \n",
    "                                 error = cf.error,\n",
    "                                 ROS = True, \n",
    "                                 LSmaxSensorNum = maxSensorNum,\n",
    "                                 ISmaxSensorNum = cf.ISsensorsNum, \n",
    "                                 initial_state = cf.initial_state,\n",
    "                                 input_sensor_types = cf.sensor_types,\n",
    "                                 acquisition_function = cf.acquisition_function,\n",
    "                                 surrogate_model = cf.surrogate_model,\n",
    "                                 acq_optimizer_type = cf.acq_optimizer_type)\n",
    "\n",
    "    history = BO.run()\n",
    "\n",
    "    with open('Results_BO/history(LS' + str(cf.LSsensorsNum) +  'IS' + str(cf.ISsensorsNum) + ')_' + str(i), 'wb') as handle:\n",
    "        pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    print(history)\n",
    "\n",
    "    print('-' * 50)\n",
    "\n",
    "    try:\n",
    "        print(cf.std_list[history.get_best_config()])\n",
    "\n",
    "    except:\n",
    "        print('The configuration was not saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {(1, 6): 54.72503667035234, (4, 4): 63.116526304289735, (7, 5): 64.23860849102844, (7, 2): 72.5536111619651, (1, 3): 74.47339313024378, (4, 1): 82.24260383675968, (4, 7): 90.89607606016276, (0, 0): 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 10, 1000)  # Generating x values from 0 to 10\n",
    "e = np.e  # Euler's number (approximately 2.71828)\n",
    "y = 0.5 * np.log10(x) + 2  # Applying the natural logarithm to x + e\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ln(x + e)')\n",
    "plt.title('Plot of ln(x + e)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 20, 1000)  # Generating x values from 0 to 10\n",
    "e = np.e  # Euler's number (approximately 2.71828)\n",
    "# y = 0.5 * (1 + np.log(x + e))  # Applying the natural logarithm to x + e\n",
    "\n",
    "y =  2 / (1 + (e**(-x)))\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ln(x + e)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_modified_function():\n",
    "    x = np.linspace(0, 10, 1000)  # Generating x values from 0 to 10\n",
    "    e = np.e  # Euler's number (approximately 2.71828)\n",
    "    y = 1 / (np.log(x + e))  # Applying the transformation to x + e\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Modified y')\n",
    "    plt.title('Plot of Modified Function')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_modified_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import SensorOptimizers.BayesianOptimization as bo\n",
    "import numpy as np\n",
    "import pickle\n",
    "import Config as cf\n",
    "\n",
    "maxSensorNum = int(np.min([(cf.space[2][0] / cf.epsilon) * (cf.space[2][1] / cf.epsilon), cf.LSsensorsNum]))\n",
    "\n",
    "\n",
    "print('----- Running BO with: \\n \\t - epsilon: ', cf.epsilon, \n",
    "      '\\n \\t - testbed: ', cf.testbed,\n",
    "      '\\n \\t - LS sensors #: ', cf.LSsensorsNum, \n",
    "      '\\n \\t - IS sensors #: ', cf.ISsensorsNum, \n",
    "      '\\n \\t - initial state: ', cf.initial_state,\n",
    "      '\\n \\t - gradient analysis: ', cf.gradient_fantacy,\n",
    "      ' \\n \\t - AF: ', cf.acquisition_function)\n",
    "\n",
    "for i in range(0, 1):\n",
    "    BO = bo.BayesianOptimization(testbed = cf.testbed,\n",
    "                                 iteration = cf.bo_iteration, \n",
    "                                 epsilon = cf.epsilon, \n",
    "                                 error = cf.error,\n",
    "                                 ROS = True, \n",
    "                                 LSmaxSensorNum = maxSensorNum,\n",
    "                                 ISmaxSensorNum = cf.ISsensorsNum, \n",
    "                                 initial_state = cf.initial_state,\n",
    "                                 input_sensor_types = cf.sensor_types,\n",
    "                                 acquisition_function = cf.acquisition_function,\n",
    "                                 surrogate_model = cf.surrogate_model,\n",
    "                                 acq_optimizer_type = cf.acq_optimizer_type)\n",
    "\n",
    "    history = BO.run()\n",
    "\n",
    "    with open('Results_BO/history(LS' + str(cf.LSsensorsNum) +  'IS' + str(cf.ISsensorsNum) + ')_' + str(i), 'wb') as handle:\n",
    "        pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample 2D matrix\n",
    "matrix = np.random.rand(10, 10)\n",
    "\n",
    "# Plot the heat map\n",
    "plt.imshow(matrix, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# Add the value inside each grid\n",
    "for i in range(matrix.shape[0]):\n",
    "    for j in range(matrix.shape[1]):\n",
    "        plt.text(j, i, '{:.2f}'.format(matrix[i, j]), ha='center', va='center', color='blue')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max([-10, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.nan > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(numbers):\n",
    "    total = sum(range(1, len(numbers) + 1))\n",
    "    weighted_sum = sum((i + 1) * num for i, num in enumerate(numbers))\n",
    "    return weighted_sum / total\n",
    "\n",
    "# Example usage\n",
    "number_list = [1, 10, 10, 10, 10]\n",
    "result = weighted_average(number_list)\n",
    "print(\"Weighted Average:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1, 1, 2, 3, 4]\n",
    "\n",
    "len(np.unique(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "d= {}\n",
    "\n",
    "np.var(d[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'iteration': 7, 'key': '[1, 3]', 'mu_plus - z_plus': -440.2802425378722, 'W': -70.01797648037211, 'norm.cdf(W)': 0.0, 'norm.pdf(W)': 0.0, 'mu_plus': 52.76819370836312, 'mu_minus': 51.162611895321646, 'var_plus': 39.54023836469091, 'var_minus': 44.44824306912302, 'self.info_map_plus[key]': [46.48009078580445, 59.05629663092179], 'self.info_map_minus[key]': [55.93570779895406, 47.32688079835312, 59.05629663092179, 42.331562353057635]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.var([46.48009078580445, 59.05629663092179]))\n",
    "print(np.mean([46.48009078580445, 59.05629663092179]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.var([55.93570779895406,\n",
    "  47.32688079835312,\n",
    "  59.05629663092179,\n",
    "  42.331562353057635]))\n",
    "print(np.mean([55.93570779895406,\n",
    "  47.32688079835312,\n",
    "  59.05629663092179,\n",
    "  42.331562353057635]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'iteration': 6, 'key': '[1, 3]', 'mu_plus - z_plus': 145.9059465649114, 'W': 23.20349211229852, 'norm.cdf(W)': 1.0, 'norm.pdf(W)': 4.879678503882637e-118, 'mu_plus': 52.76819370836312, 'mu_minus': 54.10629507607632, 'var_plus': 39.54023836469091, 'var_minus': 24.603241417532228, 'self.info_map_plus[key]': [46.48009078580445, 59.05629663092179], 'self.info_map_minus[key]': [55.93570779895406, 47.32688079835312, 59.05629663092179, 42.331562353057635]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "145.9059465649114 * 1.0 + 52.76819370836312 * 4.879678503882637e-118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'iteration': 5, 'key': '[1, 3]', 'mu_plus - z_plus': np.nan, 'W': np.nan, 'norm.cdf(W)': np.nan, 'norm.pdf(W)': np.nan, 'mu_plus': 46.48009078580445, 'mu_minus': 54.10629507607632, 'var_plus': 0.0, 'var_minus': 24.603241417532228, 'self.info_map_plus[key]': [46.48009078580445, 59.05629663092179], 'self.info_map_minus[key]': [55.93570779895406, 47.32688079835312, 59.05629663092179, 42.331562353057635]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'iteration': 4, 'key': '[1, 3]', 'mu_plus - z_plus': np.nan, 'W': np.nan, 'norm.cdf(W)': np.nan, 'norm.pdf(W)': np.nan, 'mu_plus': 46.48009078580445, 'mu_minus': 51.63129429865359, 'var_plus': 0.0, 'var_minus': 18.527975581568942, 'self.info_map_plus[key]': [46.48009078580445, 59.05629663092179], 'self.info_map_minus[key]': [55.93570779895406, 47.32688079835312, 59.05629663092179, 42.331562353057635]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'iteration': 3, 'key': '[1, 3]', 'mu_plus - z_plus': np.nan, 'W': np.nan, 'norm.cdf(W)': np.nan, 'norm.pdf(W)': np.nan, 'mu_plus': 46.48009078580445, 'mu_minus': 55.93570779895406, 'var_plus': 0.0, 'var_minus': 0.0, 'self.info_map_plus[key]': [46.48009078580445, 59.05629663092179], 'self.info_map_minus[key]': [55.93570779895406, 47.32688079835312, 59.05629663092179, 42.331562353057635]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50 * (25/55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50 * (30/55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sets\n",
    "set_a = [10, 20, 30, 40, 50]\n",
    "set_b = [1000, 2000, 3000, 4000, 5000]\n",
    "\n",
    "# Find the minimum and maximum values\n",
    "min_a, max_a = min(set_a), max(set_a)\n",
    "min_b, max_b = min(set_b), max(set_b)\n",
    "\n",
    "# Scale Set A\n",
    "scaled_a = [(x - min_a) / (max_a - min_a) for x in set_a]\n",
    "\n",
    "# Scale Set B\n",
    "scaled_b = [(x - min_b) / (max_b - min_b) for x in set_b]\n",
    "\n",
    "print(\"Scaled Set A:\", scaled_a)\n",
    "print(\"Scaled Set B:\", scaled_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def exponential_decay(initial_value, decay_rate, time):\n",
    "    return initial_value * math.exp(-decay_rate * time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_value = exponential_decay(100, 0.1, 2)\n",
    "print(decay_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def exponential_decay(initial_value, decay_rate, time):\n",
    "    return initial_value * np.exp(-decay_rate * time)\n",
    "\n",
    "# Define the parameters\n",
    "initial_value = 1\n",
    "decay_rate = 0.01  # Adjusted decay rate for convergence around time = 200\n",
    "time = np.linspace(0, 1000, 100)\n",
    "\n",
    "# Calculate the decayed values\n",
    "decay_values = exponential_decay(initial_value, decay_rate, time)\n",
    "\n",
    "# Plot the decay values\n",
    "plt.plot(time, decay_values)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Decayed Value')\n",
    "plt.title('Exponential Decay')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def custom_growth_and_decay(time):\n",
    "    values = np.zeros_like(time)\n",
    "    values[:100] = np.exp((time[:100] / 200) * np.log(2)) - 1  # Exponential growth phase\n",
    "    values[100:] = np.exp(-(time[100:] - 100) / 100)  # Exponential decay phase\n",
    "    return values\n",
    "\n",
    "# Define the time range\n",
    "time = np.linspace(0, 1000, 1000)\n",
    "\n",
    "# Calculate the values\n",
    "values = custom_growth_and_decay(time)\n",
    "\n",
    "# Plot the values\n",
    "plt.plot(time, values)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Custom Growth and Decay')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - 21.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - 67.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ceil(7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.ceil(7) / 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "A = [0 ,0, 1, 2]\n",
    "print(A.remove(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SensorOptimizers.BayesianOptimization as bo\n",
    "import numpy as np\n",
    "import pickle\n",
    "import Config as cf\n",
    "\n",
    "maxSensorNum = int(np.min([(cf.space[2][0] / cf.epsilon) * (cf.space[2][1] / cf.epsilon), cf.LSsensorsNum]))\n",
    "\n",
    "\n",
    "print('----- Running BO with: \\n \\t - epsilon: ', cf.epsilon, \n",
    "      '\\n \\t - testbed: ', cf.testbed,\n",
    "      '\\n \\t - LS sensors #: ', cf.LSsensorsNum, \n",
    "      '\\n \\t - IS sensors #: ', cf.ISsensorsNum, \n",
    "      '\\n \\t - initial state: ', cf.initial_state,\n",
    "      '\\n \\t - Acquisition Function: ', cf.acquisition_function)\n",
    "\n",
    "for i in range(0, 1):\n",
    "    BO = bo.BayesianOptimization(testbed = cf.testbed,\n",
    "                                 iteration = cf.bo_iteration, \n",
    "                                 epsilon = cf.epsilon, \n",
    "                                 error = cf.error,\n",
    "                                 ROS = True, \n",
    "                                 LSmaxSensorNum = maxSensorNum,\n",
    "                                 ISmaxSensorNum = cf.ISsensorsNum, \n",
    "                                 initial_state = cf.initial_state,\n",
    "                                 input_sensor_types = cf.sensor_types,\n",
    "                                 acquisition_function = cf.acquisition_function,\n",
    "                                 surrogate_model = cf.surrogate_model,\n",
    "                                 acq_optimizer_type = cf.acq_optimizer_type)\n",
    "\n",
    "    history = BO.run()\n",
    "\n",
    "    with open('Results_BO/AAAI new 10 _ history(LS' + str(cf.LSsensorsNum) +  'IS' + str(cf.ISsensorsNum) + ')_' + str(i), 'wb') as handle:\n",
    "        pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "\n",
    "    data = data.replace('\\t', ' ')\n",
    "    converted_data = []\n",
    "    activity_map = {}\n",
    "    \n",
    "    for line in data.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            parts = line.split(' ')\n",
    "            timestamp = parts[1]\n",
    "            sensor_name = parts[2]  + ' ' + parts[3]\n",
    "            activity = ' '.join(parts[4:])\n",
    "            \n",
    "            if sensor_name.startswith('M'):\n",
    "                if activity.endswith('begin'):\n",
    "                    activity_name = activity[:-6]\n",
    "                    activity_name = activity_name.replace(' ', '')\n",
    "                    activity_map[sensor_name] = activity_name\n",
    "                    converted_data.append((timestamp, sensor_name, activity_name))\n",
    "                elif activity.endswith('end'):\n",
    "                    if sensor_name in activity_map:\n",
    "                        activity_name = activity_map.pop(sensor_name)\n",
    "                        activity_name = activity_name.replace(' ', '')\n",
    "                        converted_data.append((timestamp, sensor_name, activity_name))\n",
    "                else:\n",
    "                    if sensor_name in activity_map:\n",
    "                        \n",
    "                        activity_name = activity_map[sensor_name]\n",
    "                        activity_name = activity_name.replace(' ', '')\n",
    "                        converted_data.append((timestamp, sensor_name, activity_name))\n",
    "    \n",
    "    return converted_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def separate_by_day(converted_data):\n",
    "    day_data = {}\n",
    "    \n",
    "    day_number = 1\n",
    "    previous_hour = 0\n",
    "\n",
    "\n",
    "    for timestamp, sensor_name, activity in converted_data:\n",
    "        if '.' in timestamp:\n",
    "            time_format = '%H:%M:%S.%f'\n",
    "        else:\n",
    "            time_format = '%H:%M:%S'\n",
    "        \n",
    "        time = datetime.strptime(timestamp, time_format)\n",
    "\n",
    "        if previous_hour > time.hour:\n",
    "            day_number = day_number + 1\n",
    "        \n",
    "        if day_number not in day_data:\n",
    "            day_data[day_number] = []\n",
    "        \n",
    "        day_data[day_number].append(timestamp + ' ' + sensor_name + ' ' + activity)\n",
    "        previous_hour = time.hour\n",
    "    \n",
    "    return day_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_activities(data):\n",
    "    unique_activities = set()\n",
    "    \n",
    "    for day in data.keys():\n",
    "        for row in data[day]:\n",
    "            activity = row.split(' ')[-1]\n",
    "            unique_activities.add(activity)\n",
    "        \n",
    "    return list(unique_activities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRealWorldDataset/aruba/data\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m convert_data(input_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_data' is not defined"
     ]
    }
   ],
   "source": [
    "input_file = 'RealWorldDataset/aruba/data'\n",
    "data = convert_data(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = separate_by_day(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_activities = get_unique_activities(D)\n",
    "\n",
    "print(\"Unique Activities:\")\n",
    "for activity in unique_activities:\n",
    "    print(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(data, train_percentage):\n",
    "    keys = list(data.keys())\n",
    "    split_index = int(len(keys) * train_percentage)\n",
    "    train_keys = keys[:split_index]\n",
    "    test_keys = keys[split_index:]\n",
    "\n",
    "\n",
    "    train_data = [item for key in train_keys for item in data[key]]\n",
    "    test_data = [item for key in test_keys for item in data[key]]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test_data(D, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_sensors(data, sensor_names):\n",
    "    filtered_data = {}\n",
    "    \n",
    "    for day, day_data in data.items():\n",
    "        filtered_day_data = []\n",
    "        for entry in day_data:\n",
    "            if entry.split(' ')[-3] in sensor_names:\n",
    "                filtered_day_data.append(entry)\n",
    "        \n",
    "        if filtered_day_data:\n",
    "            filtered_data[day] = filtered_day_data\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def filter_data_by_sensors(data, sensor_names):\n",
    "    filtered_data = []\n",
    "    \n",
    "    for day_data in data.values():\n",
    "        filtered_day_data = []\n",
    "        for entry in day_data:\n",
    "            if entry[1] in sensor_names:\n",
    "                filtered_day_data.append(entry)\n",
    "        \n",
    "        if filtered_day_data:\n",
    "            filtered_data.extend(filtered_day_data)\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = filter_data_by_sensors(D, sensor_names = ['M003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = set()\n",
    "for a in A:\n",
    "    B.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval('[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
